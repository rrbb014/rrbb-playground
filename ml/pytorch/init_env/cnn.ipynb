{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        './data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        './data',\n",
    "        train=False,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output =  model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 200 == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}\"\n",
    "                 .format(epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            \n",
    "            # batch loss aggregate\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t Loss: 2.404952\n",
      "Train Epoch: 1 [12800/60000 (21%)]\t Loss: 1.307989\n",
      "Train Epoch: 1 [25600/60000 (43%)]\t Loss: 0.994351\n",
      "Train Epoch: 1 [38400/60000 (64%)]\t Loss: 0.859094\n",
      "Train Epoch: 1 [51200/60000 (85%)]\t Loss: 0.718388\n",
      "[1] Test Loss: 0.6558, Accuracy: 74.91%\n",
      "Train Epoch: 2 [0/60000 (0%)]\t Loss: 0.849439\n",
      "Train Epoch: 2 [12800/60000 (21%)]\t Loss: 0.671565\n",
      "Train Epoch: 2 [25600/60000 (43%)]\t Loss: 0.979898\n",
      "Train Epoch: 2 [38400/60000 (64%)]\t Loss: 0.801622\n",
      "Train Epoch: 2 [51200/60000 (85%)]\t Loss: 0.719392\n",
      "[2] Test Loss: 0.5728, Accuracy: 77.73%\n",
      "Train Epoch: 3 [0/60000 (0%)]\t Loss: 0.993288\n",
      "Train Epoch: 3 [12800/60000 (21%)]\t Loss: 0.636887\n",
      "Train Epoch: 3 [25600/60000 (43%)]\t Loss: 0.751888\n",
      "Train Epoch: 3 [38400/60000 (64%)]\t Loss: 0.706934\n",
      "Train Epoch: 3 [51200/60000 (85%)]\t Loss: 0.692329\n",
      "[3] Test Loss: 0.5197, Accuracy: 79.49%\n",
      "Train Epoch: 4 [0/60000 (0%)]\t Loss: 0.701730\n",
      "Train Epoch: 4 [12800/60000 (21%)]\t Loss: 0.445242\n",
      "Train Epoch: 4 [25600/60000 (43%)]\t Loss: 0.492662\n",
      "Train Epoch: 4 [38400/60000 (64%)]\t Loss: 0.925959\n",
      "Train Epoch: 4 [51200/60000 (85%)]\t Loss: 0.517599\n",
      "[4] Test Loss: 0.4971, Accuracy: 81.71%\n",
      "Train Epoch: 5 [0/60000 (0%)]\t Loss: 0.643448\n",
      "Train Epoch: 5 [12800/60000 (21%)]\t Loss: 0.601020\n",
      "Train Epoch: 5 [25600/60000 (43%)]\t Loss: 0.533003\n",
      "Train Epoch: 5 [38400/60000 (64%)]\t Loss: 0.630634\n",
      "Train Epoch: 5 [51200/60000 (85%)]\t Loss: 0.588307\n",
      "[5] Test Loss: 0.4763, Accuracy: 82.58%\n",
      "Train Epoch: 6 [0/60000 (0%)]\t Loss: 0.590561\n",
      "Train Epoch: 6 [12800/60000 (21%)]\t Loss: 0.726294\n",
      "Train Epoch: 6 [25600/60000 (43%)]\t Loss: 0.575636\n",
      "Train Epoch: 6 [38400/60000 (64%)]\t Loss: 0.412198\n",
      "Train Epoch: 6 [51200/60000 (85%)]\t Loss: 0.521105\n",
      "[6] Test Loss: 0.4572, Accuracy: 83.28%\n",
      "Train Epoch: 7 [0/60000 (0%)]\t Loss: 0.424690\n",
      "Train Epoch: 7 [12800/60000 (21%)]\t Loss: 0.458299\n",
      "Train Epoch: 7 [25600/60000 (43%)]\t Loss: 0.676306\n",
      "Train Epoch: 7 [38400/60000 (64%)]\t Loss: 0.646487\n",
      "Train Epoch: 7 [51200/60000 (85%)]\t Loss: 0.586690\n",
      "[7] Test Loss: 0.4436, Accuracy: 83.60%\n",
      "Train Epoch: 8 [0/60000 (0%)]\t Loss: 0.426420\n",
      "Train Epoch: 8 [12800/60000 (21%)]\t Loss: 0.495156\n",
      "Train Epoch: 8 [25600/60000 (43%)]\t Loss: 0.505871\n",
      "Train Epoch: 8 [38400/60000 (64%)]\t Loss: 0.569937\n",
      "Train Epoch: 8 [51200/60000 (85%)]\t Loss: 0.475087\n",
      "[8] Test Loss: 0.4289, Accuracy: 84.36%\n",
      "Train Epoch: 9 [0/60000 (0%)]\t Loss: 0.360050\n",
      "Train Epoch: 9 [12800/60000 (21%)]\t Loss: 0.762564\n",
      "Train Epoch: 9 [25600/60000 (43%)]\t Loss: 0.410636\n",
      "Train Epoch: 9 [38400/60000 (64%)]\t Loss: 0.703668\n",
      "Train Epoch: 9 [51200/60000 (85%)]\t Loss: 0.402530\n",
      "[9] Test Loss: 0.4139, Accuracy: 84.95%\n",
      "Train Epoch: 10 [0/60000 (0%)]\t Loss: 0.636535\n",
      "Train Epoch: 10 [12800/60000 (21%)]\t Loss: 0.457888\n",
      "Train Epoch: 10 [25600/60000 (43%)]\t Loss: 0.629496\n",
      "Train Epoch: 10 [38400/60000 (64%)]\t Loss: 0.449432\n",
      "Train Epoch: 10 [51200/60000 (85%)]\t Loss: 0.362559\n",
      "[10] Test Loss: 0.4012, Accuracy: 85.36%\n",
      "Train Epoch: 11 [0/60000 (0%)]\t Loss: 0.548657\n",
      "Train Epoch: 11 [12800/60000 (21%)]\t Loss: 0.405362\n",
      "Train Epoch: 11 [25600/60000 (43%)]\t Loss: 0.652937\n",
      "Train Epoch: 11 [38400/60000 (64%)]\t Loss: 0.520065\n",
      "Train Epoch: 11 [51200/60000 (85%)]\t Loss: 0.808175\n",
      "[11] Test Loss: 0.3930, Accuracy: 85.69%\n",
      "Train Epoch: 12 [0/60000 (0%)]\t Loss: 1.052337\n",
      "Train Epoch: 12 [12800/60000 (21%)]\t Loss: 0.465431\n",
      "Train Epoch: 12 [25600/60000 (43%)]\t Loss: 0.547549\n",
      "Train Epoch: 12 [38400/60000 (64%)]\t Loss: 0.468346\n",
      "Train Epoch: 12 [51200/60000 (85%)]\t Loss: 0.551805\n",
      "[12] Test Loss: 0.3802, Accuracy: 85.98%\n",
      "Train Epoch: 13 [0/60000 (0%)]\t Loss: 0.502157\n",
      "Train Epoch: 13 [12800/60000 (21%)]\t Loss: 0.487338\n",
      "Train Epoch: 13 [25600/60000 (43%)]\t Loss: 0.571351\n",
      "Train Epoch: 13 [38400/60000 (64%)]\t Loss: 0.484025\n",
      "Train Epoch: 13 [51200/60000 (85%)]\t Loss: 0.513228\n",
      "[13] Test Loss: 0.3743, Accuracy: 86.27%\n",
      "Train Epoch: 14 [0/60000 (0%)]\t Loss: 0.410669\n",
      "Train Epoch: 14 [12800/60000 (21%)]\t Loss: 0.306137\n",
      "Train Epoch: 14 [25600/60000 (43%)]\t Loss: 0.380563\n",
      "Train Epoch: 14 [38400/60000 (64%)]\t Loss: 0.456639\n",
      "Train Epoch: 14 [51200/60000 (85%)]\t Loss: 0.535367\n",
      "[14] Test Loss: 0.3684, Accuracy: 86.78%\n",
      "Train Epoch: 15 [0/60000 (0%)]\t Loss: 0.381382\n",
      "Train Epoch: 15 [12800/60000 (21%)]\t Loss: 0.375356\n",
      "Train Epoch: 15 [25600/60000 (43%)]\t Loss: 0.294530\n",
      "Train Epoch: 15 [38400/60000 (64%)]\t Loss: 0.575818\n",
      "Train Epoch: 15 [51200/60000 (85%)]\t Loss: 0.321966\n",
      "[15] Test Loss: 0.3628, Accuracy: 86.78%\n",
      "Train Epoch: 16 [0/60000 (0%)]\t Loss: 0.338263\n",
      "Train Epoch: 16 [12800/60000 (21%)]\t Loss: 0.375618\n",
      "Train Epoch: 16 [25600/60000 (43%)]\t Loss: 0.549048\n",
      "Train Epoch: 16 [38400/60000 (64%)]\t Loss: 0.536917\n",
      "Train Epoch: 16 [51200/60000 (85%)]\t Loss: 0.420214\n",
      "[16] Test Loss: 0.3580, Accuracy: 86.89%\n",
      "Train Epoch: 17 [0/60000 (0%)]\t Loss: 0.475771\n",
      "Train Epoch: 17 [12800/60000 (21%)]\t Loss: 0.430181\n",
      "Train Epoch: 17 [25600/60000 (43%)]\t Loss: 0.600765\n",
      "Train Epoch: 17 [38400/60000 (64%)]\t Loss: 0.438758\n",
      "Train Epoch: 17 [51200/60000 (85%)]\t Loss: 0.353074\n",
      "[17] Test Loss: 0.3524, Accuracy: 87.05%\n",
      "Train Epoch: 18 [0/60000 (0%)]\t Loss: 0.336250\n",
      "Train Epoch: 18 [12800/60000 (21%)]\t Loss: 0.449869\n",
      "Train Epoch: 18 [25600/60000 (43%)]\t Loss: 0.349011\n",
      "Train Epoch: 18 [38400/60000 (64%)]\t Loss: 0.520804\n",
      "Train Epoch: 18 [51200/60000 (85%)]\t Loss: 0.261316\n",
      "[18] Test Loss: 0.3470, Accuracy: 87.35%\n",
      "Train Epoch: 19 [0/60000 (0%)]\t Loss: 0.404165\n",
      "Train Epoch: 19 [12800/60000 (21%)]\t Loss: 0.598765\n",
      "Train Epoch: 19 [25600/60000 (43%)]\t Loss: 0.602030\n",
      "Train Epoch: 19 [38400/60000 (64%)]\t Loss: 0.577642\n",
      "Train Epoch: 19 [51200/60000 (85%)]\t Loss: 0.546135\n",
      "[19] Test Loss: 0.3464, Accuracy: 87.27%\n",
      "Train Epoch: 20 [0/60000 (0%)]\t Loss: 0.491971\n",
      "Train Epoch: 20 [12800/60000 (21%)]\t Loss: 0.411932\n",
      "Train Epoch: 20 [25600/60000 (43%)]\t Loss: 0.387724\n",
      "Train Epoch: 20 [38400/60000 (64%)]\t Loss: 0.485577\n",
      "Train Epoch: 20 [51200/60000 (85%)]\t Loss: 0.529728\n",
      "[20] Test Loss: 0.3476, Accuracy: 86.86%\n",
      "Train Epoch: 21 [0/60000 (0%)]\t Loss: 0.433506\n",
      "Train Epoch: 21 [12800/60000 (21%)]\t Loss: 0.371572\n",
      "Train Epoch: 21 [25600/60000 (43%)]\t Loss: 0.498949\n",
      "Train Epoch: 21 [38400/60000 (64%)]\t Loss: 0.493147\n",
      "Train Epoch: 21 [51200/60000 (85%)]\t Loss: 0.323994\n",
      "[21] Test Loss: 0.3391, Accuracy: 87.69%\n",
      "Train Epoch: 22 [0/60000 (0%)]\t Loss: 0.581261\n",
      "Train Epoch: 22 [12800/60000 (21%)]\t Loss: 0.472375\n",
      "Train Epoch: 22 [25600/60000 (43%)]\t Loss: 0.561068\n",
      "Train Epoch: 22 [38400/60000 (64%)]\t Loss: 0.391216\n",
      "Train Epoch: 22 [51200/60000 (85%)]\t Loss: 0.533334\n",
      "[22] Test Loss: 0.3411, Accuracy: 87.42%\n",
      "Train Epoch: 23 [0/60000 (0%)]\t Loss: 0.470627\n",
      "Train Epoch: 23 [12800/60000 (21%)]\t Loss: 0.563350\n",
      "Train Epoch: 23 [25600/60000 (43%)]\t Loss: 0.321373\n",
      "Train Epoch: 23 [38400/60000 (64%)]\t Loss: 0.392667\n",
      "Train Epoch: 23 [51200/60000 (85%)]\t Loss: 0.347331\n",
      "[23] Test Loss: 0.3408, Accuracy: 87.28%\n",
      "Train Epoch: 24 [0/60000 (0%)]\t Loss: 0.459463\n",
      "Train Epoch: 24 [12800/60000 (21%)]\t Loss: 0.339538\n",
      "Train Epoch: 24 [25600/60000 (43%)]\t Loss: 0.569715\n",
      "Train Epoch: 24 [38400/60000 (64%)]\t Loss: 0.138496\n",
      "Train Epoch: 24 [51200/60000 (85%)]\t Loss: 0.433954\n",
      "[24] Test Loss: 0.3375, Accuracy: 87.72%\n",
      "Train Epoch: 25 [0/60000 (0%)]\t Loss: 0.289645\n",
      "Train Epoch: 25 [12800/60000 (21%)]\t Loss: 0.511245\n",
      "Train Epoch: 25 [25600/60000 (43%)]\t Loss: 0.420867\n",
      "Train Epoch: 25 [38400/60000 (64%)]\t Loss: 0.583874\n",
      "Train Epoch: 25 [51200/60000 (85%)]\t Loss: 0.312988\n",
      "[25] Test Loss: 0.3320, Accuracy: 87.77%\n",
      "Train Epoch: 26 [0/60000 (0%)]\t Loss: 0.263501\n",
      "Train Epoch: 26 [12800/60000 (21%)]\t Loss: 0.286837\n",
      "Train Epoch: 26 [25600/60000 (43%)]\t Loss: 0.315361\n",
      "Train Epoch: 26 [38400/60000 (64%)]\t Loss: 0.397788\n",
      "Train Epoch: 26 [51200/60000 (85%)]\t Loss: 0.296802\n",
      "[26] Test Loss: 0.3343, Accuracy: 87.86%\n",
      "Train Epoch: 27 [0/60000 (0%)]\t Loss: 0.601320\n",
      "Train Epoch: 27 [12800/60000 (21%)]\t Loss: 0.544989\n",
      "Train Epoch: 27 [25600/60000 (43%)]\t Loss: 0.640769\n",
      "Train Epoch: 27 [38400/60000 (64%)]\t Loss: 0.356975\n",
      "Train Epoch: 27 [51200/60000 (85%)]\t Loss: 0.362597\n",
      "[27] Test Loss: 0.3346, Accuracy: 88.00%\n",
      "Train Epoch: 28 [0/60000 (0%)]\t Loss: 0.474136\n",
      "Train Epoch: 28 [12800/60000 (21%)]\t Loss: 0.428935\n",
      "Train Epoch: 28 [25600/60000 (43%)]\t Loss: 0.444052\n",
      "Train Epoch: 28 [38400/60000 (64%)]\t Loss: 0.567748\n",
      "Train Epoch: 28 [51200/60000 (85%)]\t Loss: 0.420988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28] Test Loss: 0.3291, Accuracy: 87.77%\n",
      "Train Epoch: 29 [0/60000 (0%)]\t Loss: 0.501616\n",
      "Train Epoch: 29 [12800/60000 (21%)]\t Loss: 0.542850\n",
      "Train Epoch: 29 [25600/60000 (43%)]\t Loss: 0.315853\n",
      "Train Epoch: 29 [38400/60000 (64%)]\t Loss: 0.504850\n",
      "Train Epoch: 29 [51200/60000 (85%)]\t Loss: 0.362190\n",
      "[29] Test Loss: 0.3325, Accuracy: 87.86%\n",
      "Train Epoch: 30 [0/60000 (0%)]\t Loss: 0.491274\n",
      "Train Epoch: 30 [12800/60000 (21%)]\t Loss: 0.277072\n",
      "Train Epoch: 30 [25600/60000 (43%)]\t Loss: 0.265356\n",
      "Train Epoch: 30 [38400/60000 (64%)]\t Loss: 0.338371\n",
      "Train Epoch: 30 [51200/60000 (85%)]\t Loss: 0.297901\n",
      "[30] Test Loss: 0.3284, Accuracy: 87.80%\n",
      "Train Epoch: 31 [0/60000 (0%)]\t Loss: 0.375684\n",
      "Train Epoch: 31 [12800/60000 (21%)]\t Loss: 0.480342\n",
      "Train Epoch: 31 [25600/60000 (43%)]\t Loss: 0.589811\n",
      "Train Epoch: 31 [38400/60000 (64%)]\t Loss: 0.596975\n",
      "Train Epoch: 31 [51200/60000 (85%)]\t Loss: 0.412153\n",
      "[31] Test Loss: 0.3240, Accuracy: 88.18%\n",
      "Train Epoch: 32 [0/60000 (0%)]\t Loss: 0.437041\n",
      "Train Epoch: 32 [12800/60000 (21%)]\t Loss: 0.337980\n",
      "Train Epoch: 32 [25600/60000 (43%)]\t Loss: 0.510926\n",
      "Train Epoch: 32 [38400/60000 (64%)]\t Loss: 0.391435\n",
      "Train Epoch: 32 [51200/60000 (85%)]\t Loss: 0.460674\n",
      "[32] Test Loss: 0.3209, Accuracy: 88.28%\n",
      "Train Epoch: 33 [0/60000 (0%)]\t Loss: 0.534743\n",
      "Train Epoch: 33 [12800/60000 (21%)]\t Loss: 0.422883\n",
      "Train Epoch: 33 [25600/60000 (43%)]\t Loss: 0.366253\n",
      "Train Epoch: 33 [38400/60000 (64%)]\t Loss: 0.414502\n",
      "Train Epoch: 33 [51200/60000 (85%)]\t Loss: 0.229042\n",
      "[33] Test Loss: 0.3238, Accuracy: 88.26%\n",
      "Train Epoch: 34 [0/60000 (0%)]\t Loss: 0.319985\n",
      "Train Epoch: 34 [12800/60000 (21%)]\t Loss: 0.288488\n",
      "Train Epoch: 34 [25600/60000 (43%)]\t Loss: 0.607042\n",
      "Train Epoch: 34 [38400/60000 (64%)]\t Loss: 0.446433\n",
      "Train Epoch: 34 [51200/60000 (85%)]\t Loss: 0.380622\n",
      "[34] Test Loss: 0.3190, Accuracy: 88.49%\n",
      "Train Epoch: 35 [0/60000 (0%)]\t Loss: 0.526964\n",
      "Train Epoch: 35 [12800/60000 (21%)]\t Loss: 0.393387\n",
      "Train Epoch: 35 [25600/60000 (43%)]\t Loss: 0.520166\n",
      "Train Epoch: 35 [38400/60000 (64%)]\t Loss: 0.523959\n",
      "Train Epoch: 35 [51200/60000 (85%)]\t Loss: 0.465184\n",
      "[35] Test Loss: 0.3199, Accuracy: 88.39%\n",
      "Train Epoch: 36 [0/60000 (0%)]\t Loss: 0.368492\n",
      "Train Epoch: 36 [12800/60000 (21%)]\t Loss: 0.274295\n",
      "Train Epoch: 36 [25600/60000 (43%)]\t Loss: 0.411241\n",
      "Train Epoch: 36 [38400/60000 (64%)]\t Loss: 0.459234\n",
      "Train Epoch: 36 [51200/60000 (85%)]\t Loss: 0.587322\n",
      "[36] Test Loss: 0.3182, Accuracy: 88.42%\n",
      "Train Epoch: 37 [0/60000 (0%)]\t Loss: 0.389292\n",
      "Train Epoch: 37 [12800/60000 (21%)]\t Loss: 0.323189\n",
      "Train Epoch: 37 [25600/60000 (43%)]\t Loss: 0.288610\n",
      "Train Epoch: 37 [38400/60000 (64%)]\t Loss: 0.402161\n",
      "Train Epoch: 37 [51200/60000 (85%)]\t Loss: 0.460130\n",
      "[37] Test Loss: 0.3193, Accuracy: 88.10%\n",
      "Train Epoch: 38 [0/60000 (0%)]\t Loss: 0.301506\n",
      "Train Epoch: 38 [12800/60000 (21%)]\t Loss: 0.513097\n",
      "Train Epoch: 38 [25600/60000 (43%)]\t Loss: 0.247374\n",
      "Train Epoch: 38 [38400/60000 (64%)]\t Loss: 0.348978\n",
      "Train Epoch: 38 [51200/60000 (85%)]\t Loss: 0.346326\n",
      "[38] Test Loss: 0.3161, Accuracy: 88.17%\n",
      "Train Epoch: 39 [0/60000 (0%)]\t Loss: 0.338451\n",
      "Train Epoch: 39 [12800/60000 (21%)]\t Loss: 0.534125\n",
      "Train Epoch: 39 [25600/60000 (43%)]\t Loss: 0.420918\n",
      "Train Epoch: 39 [38400/60000 (64%)]\t Loss: 0.474607\n",
      "Train Epoch: 39 [51200/60000 (85%)]\t Loss: 0.302405\n",
      "[39] Test Loss: 0.3183, Accuracy: 88.23%\n",
      "Train Epoch: 40 [0/60000 (0%)]\t Loss: 0.374138\n",
      "Train Epoch: 40 [12800/60000 (21%)]\t Loss: 0.452652\n",
      "Train Epoch: 40 [25600/60000 (43%)]\t Loss: 0.603123\n",
      "Train Epoch: 40 [38400/60000 (64%)]\t Loss: 0.256850\n",
      "Train Epoch: 40 [51200/60000 (85%)]\t Loss: 0.379664\n",
      "[40] Test Loss: 0.3127, Accuracy: 88.57%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print(\"[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%\".format(epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
